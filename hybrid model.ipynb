{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b37b9d-073d-4bcc-b0bb-1f4e78ebf833",
   "metadata": {},
   "source": [
    "<h5 style=\"color:rgba(0, 0, 178, 0.6);\">This code hidden warrnings</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fdbc950-9f44-4676-9121-0f1f0cfe169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8469e6-f256-403d-a915-f3604a9bdfec",
   "metadata": {},
   "source": [
    "<h5 style=\"color:rgba(0, 0, 178, 0.6);\">Install librarys that we need</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d65697f5-85e1-46e7-b3f3-8b723917079f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"bmh\")\n",
    "from tensorflow import keras\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "790a20e4-9280-4574-bfa3-e669701c0105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bhp</th>\n",
       "      <th>bht</th>\n",
       "      <th>dp_tubing</th>\n",
       "      <th>AVG_CHOKE_SIZE_P</th>\n",
       "      <th>QG</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-07-24</th>\n",
       "      <td>1.926270</td>\n",
       "      <td>0.35220</td>\n",
       "      <td>26.123040</td>\n",
       "      <td>3.256548</td>\n",
       "      <td>9505.611429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-25</th>\n",
       "      <td>163.594260</td>\n",
       "      <td>60.31574</td>\n",
       "      <td>61.473080</td>\n",
       "      <td>8.549131</td>\n",
       "      <td>108940.110000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.464222</td>\n",
       "      <td>257479.142857</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.536987</td>\n",
       "      <td>112755.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-31</th>\n",
       "      <td>273.946931</td>\n",
       "      <td>105.55137</td>\n",
       "      <td>179.382345</td>\n",
       "      <td>2.540804</td>\n",
       "      <td>137705.269214</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bhp        bht   dp_tubing  AVG_CHOKE_SIZE_P  \\\n",
       "date                                                              \n",
       "2013-07-24    1.926270    0.35220   26.123040          3.256548   \n",
       "2013-07-25  163.594260   60.31574   61.473080          8.549131   \n",
       "2013-07-28    0.000000    0.00000    0.000000          2.464222   \n",
       "2013-07-29    0.000000    0.00000    0.000000          2.536987   \n",
       "2013-07-31  273.946931  105.55137  179.382345          2.540804   \n",
       "\n",
       "                       QG  Time  \n",
       "date                             \n",
       "2013-07-24    9505.611429     0  \n",
       "2013-07-25  108940.110000     1  \n",
       "2013-07-28  257479.142857     4  \n",
       "2013-07-29  112755.000000     5  \n",
       "2013-07-31  137705.269214     7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the orginal data from the csv file\n",
    "df1 = pd.read_csv(\"well2.csv\")\n",
    "df1['date'] = pd.to_datetime(df1['date'], errors='coerce') #convert date column to datetime format\n",
    "# =========================================\n",
    "# create a dummy date time with freq = 1D to see which days we have no data\n",
    "df = pd.DataFrame({\n",
    "    'date': pd.date_range(start='2013-07-24', periods=1152, freq='D')\n",
    "})\n",
    "# =========================================\n",
    "# Merge on the 'date' column, using 'left' join to keep all dates from df1\n",
    "df = df.merge(df1, on='date', how='left')\n",
    "\n",
    "df = df[[\n",
    "    \"date\", \"bhp\", \"bht\",\n",
    "    \"dp_tubing\", \"AVG_CHOKE_SIZE_P\",\n",
    "    \"QG\"]]\n",
    "df.set_index('date', inplace=True)\n",
    "df['Time'] = np.arange(len(df.index))\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efda4499-9d8b-4cdb-b74b-1b8cf0069d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lags(ts, lags, lead_time=1):\n",
    "    return pd.concat(\n",
    "        {\n",
    "            f'y_lag_{i}': ts.shift(i)\n",
    "            for i in range(lead_time, lags + lead_time)\n",
    "        },\n",
    "        axis=1)\n",
    "\n",
    "def make_roling_lag(df, name=\"QG\"):\n",
    "    return pd.concat(\n",
    "        [\n",
    "            df.shift(1).rolling(7).mean().rename(f\"{name}_lagged_mean_7D\"),\n",
    "            df.shift(1).rolling(7).max().rename(f\"{name}_lagged_max_7D\"),\n",
    "            df.shift(1).rolling(7).min().rename(f\"{name}_lagged_min_7D\"),\n",
    "            df.shift(1).rolling(15).mean().rename(f\"{name}_lagged_mean_15D\"),\n",
    "            df.shift(1).rolling(15).max().rename(f\"{name}_lagged_max_15D\"),\n",
    "            df.shift(1).rolling(15).min().rename(f\"{name}_lagged_min_15D\"),\n",
    "            df.shift(1).rolling(30).mean().rename(f\"{name}_lagged_mean_30D\"),\n",
    "            df.shift(1).rolling(30).max().rename(f\"{name}_lagged_max_30D\"),\n",
    "            df.shift(1).rolling(30).min().rename(f\"{name}_lagged_min_30D\"),\n",
    "        ],\n",
    "        axis=\"columns\"\n",
    "    )\n",
    "\n",
    "def make_multistep_target(ts, steps):\n",
    "    return pd.concat(\n",
    "        {f'y_step_{i + 1}': ts.shift(-i)\n",
    "         for i in range(steps)},\n",
    "        axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "372fc8f6-bf6e-466d-a788-38fd220cfd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bhp</th>\n",
       "      <th>bht</th>\n",
       "      <th>dp_tubing</th>\n",
       "      <th>AVG_CHOKE_SIZE_P</th>\n",
       "      <th>QG</th>\n",
       "      <th>Time</th>\n",
       "      <th>y_lag_1 bhp</th>\n",
       "      <th>y_lag_1 bht</th>\n",
       "      <th>y_lag_1 dp_tubing</th>\n",
       "      <th>y_lag_1 AVG_CHOKE_SIZE_P</th>\n",
       "      <th>...</th>\n",
       "      <th>dp_tubing_lagged_min_30D</th>\n",
       "      <th>AVG_CHOKE_SIZE_P_lagged_mean_7D</th>\n",
       "      <th>AVG_CHOKE_SIZE_P_lagged_max_7D</th>\n",
       "      <th>AVG_CHOKE_SIZE_P_lagged_min_7D</th>\n",
       "      <th>AVG_CHOKE_SIZE_P_lagged_mean_15D</th>\n",
       "      <th>AVG_CHOKE_SIZE_P_lagged_max_15D</th>\n",
       "      <th>AVG_CHOKE_SIZE_P_lagged_min_15D</th>\n",
       "      <th>AVG_CHOKE_SIZE_P_lagged_mean_30D</th>\n",
       "      <th>AVG_CHOKE_SIZE_P_lagged_max_30D</th>\n",
       "      <th>AVG_CHOKE_SIZE_P_lagged_min_30D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-07-24</th>\n",
       "      <td>1.926270</td>\n",
       "      <td>0.352200</td>\n",
       "      <td>26.123040</td>\n",
       "      <td>3.256548</td>\n",
       "      <td>9505.611429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-25</th>\n",
       "      <td>163.594260</td>\n",
       "      <td>60.315740</td>\n",
       "      <td>61.473080</td>\n",
       "      <td>8.549131</td>\n",
       "      <td>108940.110000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.926270</td>\n",
       "      <td>0.352200</td>\n",
       "      <td>26.123040</td>\n",
       "      <td>3.256548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.464222</td>\n",
       "      <td>257479.142857</td>\n",
       "      <td>4</td>\n",
       "      <td>163.594260</td>\n",
       "      <td>60.315740</td>\n",
       "      <td>61.473080</td>\n",
       "      <td>8.549131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.536987</td>\n",
       "      <td>112755.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.464222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-31</th>\n",
       "      <td>273.946931</td>\n",
       "      <td>105.551370</td>\n",
       "      <td>179.382345</td>\n",
       "      <td>2.540804</td>\n",
       "      <td>137705.269214</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.536987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-13</th>\n",
       "      <td>253.399422</td>\n",
       "      <td>105.266981</td>\n",
       "      <td>226.400814</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>88042.160000</td>\n",
       "      <td>1147</td>\n",
       "      <td>253.658108</td>\n",
       "      <td>105.259036</td>\n",
       "      <td>226.680342</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>223.897904</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.722222</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.916667</td>\n",
       "      <td>99.368745</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-14</th>\n",
       "      <td>253.209915</td>\n",
       "      <td>105.271539</td>\n",
       "      <td>226.255384</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>90188.970000</td>\n",
       "      <td>1148</td>\n",
       "      <td>253.399422</td>\n",
       "      <td>105.266981</td>\n",
       "      <td>226.400814</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>223.897904</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.722222</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.916667</td>\n",
       "      <td>99.420539</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-15</th>\n",
       "      <td>252.938710</td>\n",
       "      <td>105.274111</td>\n",
       "      <td>226.036656</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>91890.070000</td>\n",
       "      <td>1149</td>\n",
       "      <td>253.209915</td>\n",
       "      <td>105.271539</td>\n",
       "      <td>226.255384</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>223.897904</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.722222</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.916667</td>\n",
       "      <td>99.472771</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-16</th>\n",
       "      <td>252.892344</td>\n",
       "      <td>105.275896</td>\n",
       "      <td>226.022291</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>91579.730000</td>\n",
       "      <td>1150</td>\n",
       "      <td>252.938710</td>\n",
       "      <td>105.274111</td>\n",
       "      <td>226.036656</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>223.897904</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.722222</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.916667</td>\n",
       "      <td>99.524831</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-17</th>\n",
       "      <td>253.546058</td>\n",
       "      <td>105.279492</td>\n",
       "      <td>226.081196</td>\n",
       "      <td>73.763718</td>\n",
       "      <td>93289.481507</td>\n",
       "      <td>1151</td>\n",
       "      <td>252.892344</td>\n",
       "      <td>105.275896</td>\n",
       "      <td>226.022291</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>223.897904</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.722222</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.916667</td>\n",
       "      <td>99.576560</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1119 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bhp         bht   dp_tubing  AVG_CHOKE_SIZE_P  \\\n",
       "date                                                               \n",
       "2013-07-24    1.926270    0.352200   26.123040          3.256548   \n",
       "2013-07-25  163.594260   60.315740   61.473080          8.549131   \n",
       "2013-07-28    0.000000    0.000000    0.000000          2.464222   \n",
       "2013-07-29    0.000000    0.000000    0.000000          2.536987   \n",
       "2013-07-31  273.946931  105.551370  179.382345          2.540804   \n",
       "...                ...         ...         ...               ...   \n",
       "2016-09-13  253.399422  105.266981  226.400814        100.000000   \n",
       "2016-09-14  253.209915  105.271539  226.255384        100.000000   \n",
       "2016-09-15  252.938710  105.274111  226.036656        100.000000   \n",
       "2016-09-16  252.892344  105.275896  226.022291        100.000000   \n",
       "2016-09-17  253.546058  105.279492  226.081196         73.763718   \n",
       "\n",
       "                       QG  Time  y_lag_1 bhp  y_lag_1 bht  y_lag_1 dp_tubing  \\\n",
       "date                                                                           \n",
       "2013-07-24    9505.611429     0     0.000000     0.000000           0.000000   \n",
       "2013-07-25  108940.110000     1     1.926270     0.352200          26.123040   \n",
       "2013-07-28  257479.142857     4   163.594260    60.315740          61.473080   \n",
       "2013-07-29  112755.000000     5     0.000000     0.000000           0.000000   \n",
       "2013-07-31  137705.269214     7     0.000000     0.000000           0.000000   \n",
       "...                   ...   ...          ...          ...                ...   \n",
       "2016-09-13   88042.160000  1147   253.658108   105.259036         226.680342   \n",
       "2016-09-14   90188.970000  1148   253.399422   105.266981         226.400814   \n",
       "2016-09-15   91890.070000  1149   253.209915   105.271539         226.255384   \n",
       "2016-09-16   91579.730000  1150   252.938710   105.274111         226.036656   \n",
       "2016-09-17   93289.481507  1151   252.892344   105.275896         226.022291   \n",
       "\n",
       "            y_lag_1 AVG_CHOKE_SIZE_P  ...  dp_tubing_lagged_min_30D  \\\n",
       "date                                  ...                             \n",
       "2013-07-24                  0.000000  ...                  0.000000   \n",
       "2013-07-25                  3.256548  ...                  0.000000   \n",
       "2013-07-28                  8.549131  ...                  0.000000   \n",
       "2013-07-29                  2.464222  ...                  0.000000   \n",
       "2013-07-31                  2.536987  ...                  0.000000   \n",
       "...                              ...  ...                       ...   \n",
       "2016-09-13                100.000000  ...                223.897904   \n",
       "2016-09-14                100.000000  ...                223.897904   \n",
       "2016-09-15                100.000000  ...                223.897904   \n",
       "2016-09-16                100.000000  ...                223.897904   \n",
       "2016-09-17                100.000000  ...                223.897904   \n",
       "\n",
       "            AVG_CHOKE_SIZE_P_lagged_mean_7D  AVG_CHOKE_SIZE_P_lagged_max_7D  \\\n",
       "date                                                                          \n",
       "2013-07-24                              0.0                             0.0   \n",
       "2013-07-25                              0.0                             0.0   \n",
       "2013-07-28                              0.0                             0.0   \n",
       "2013-07-29                              0.0                             0.0   \n",
       "2013-07-31                              0.0                             0.0   \n",
       "...                                     ...                             ...   \n",
       "2016-09-13                            100.0                           100.0   \n",
       "2016-09-14                            100.0                           100.0   \n",
       "2016-09-15                            100.0                           100.0   \n",
       "2016-09-16                            100.0                           100.0   \n",
       "2016-09-17                            100.0                           100.0   \n",
       "\n",
       "            AVG_CHOKE_SIZE_P_lagged_min_7D  AVG_CHOKE_SIZE_P_lagged_mean_15D  \\\n",
       "date                                                                           \n",
       "2013-07-24                             0.0                          0.000000   \n",
       "2013-07-25                             0.0                          0.000000   \n",
       "2013-07-28                             0.0                          0.000000   \n",
       "2013-07-29                             0.0                          0.000000   \n",
       "2013-07-31                             0.0                          0.000000   \n",
       "...                                    ...                               ...   \n",
       "2016-09-13                           100.0                         99.722222   \n",
       "2016-09-14                           100.0                         99.722222   \n",
       "2016-09-15                           100.0                         99.722222   \n",
       "2016-09-16                           100.0                         99.722222   \n",
       "2016-09-17                           100.0                         99.722222   \n",
       "\n",
       "            AVG_CHOKE_SIZE_P_lagged_max_15D  AVG_CHOKE_SIZE_P_lagged_min_15D  \\\n",
       "date                                                                           \n",
       "2013-07-24                              0.0                         0.000000   \n",
       "2013-07-25                              0.0                         0.000000   \n",
       "2013-07-28                              0.0                         0.000000   \n",
       "2013-07-29                              0.0                         0.000000   \n",
       "2013-07-31                              0.0                         0.000000   \n",
       "...                                     ...                              ...   \n",
       "2016-09-13                            100.0                        97.916667   \n",
       "2016-09-14                            100.0                        97.916667   \n",
       "2016-09-15                            100.0                        97.916667   \n",
       "2016-09-16                            100.0                        97.916667   \n",
       "2016-09-17                            100.0                        97.916667   \n",
       "\n",
       "            AVG_CHOKE_SIZE_P_lagged_mean_30D  AVG_CHOKE_SIZE_P_lagged_max_30D  \\\n",
       "date                                                                            \n",
       "2013-07-24                          0.000000                              0.0   \n",
       "2013-07-25                          0.000000                              0.0   \n",
       "2013-07-28                          0.000000                              0.0   \n",
       "2013-07-29                          0.000000                              0.0   \n",
       "2013-07-31                          0.000000                              0.0   \n",
       "...                                      ...                              ...   \n",
       "2016-09-13                         99.368745                            100.0   \n",
       "2016-09-14                         99.420539                            100.0   \n",
       "2016-09-15                         99.472771                            100.0   \n",
       "2016-09-16                         99.524831                            100.0   \n",
       "2016-09-17                         99.576560                            100.0   \n",
       "\n",
       "            AVG_CHOKE_SIZE_P_lagged_min_30D  \n",
       "date                                         \n",
       "2013-07-24                         0.000000  \n",
       "2013-07-25                         0.000000  \n",
       "2013-07-28                         0.000000  \n",
       "2013-07-29                         0.000000  \n",
       "2013-07-31                         0.000000  \n",
       "...                                     ...  \n",
       "2016-09-13                        97.916667  \n",
       "2016-09-14                        97.916667  \n",
       "2016-09-15                        97.916667  \n",
       "2016-09-16                        97.916667  \n",
       "2016-09-17                        97.916667  \n",
       "\n",
       "[1119 rows x 93 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_terms = [\"bhp\", \"bht\", \"dp_tubing\", \"AVG_CHOKE_SIZE_P\", \"Time\"]\n",
    "X0=make_lags(df[search_terms], lags=4)\n",
    "X0.columns = [' '.join(col).strip() for col in X0.columns.values]\n",
    "\n",
    "search_terms = [\"bhp\", \"bht\", \"dp_tubing\", \"AVG_CHOKE_SIZE_P\", \"Time\", \"QG\"]\n",
    "\n",
    "\n",
    "\n",
    "lags=make_lags(df[search_terms], lags=7)\n",
    "lags.columns = [' '.join(col).strip() for col in lags.columns.values]\n",
    "lagged_df = pd.concat(\n",
    "    [\n",
    "        df,\n",
    "        lags,\n",
    "        make_roling_lag(df[\"QG\"], name=\"QG\"),\n",
    "        make_roling_lag(df[\"bhp\"], name=\"bhp\"),\n",
    "        make_roling_lag(df[\"bht\"], name=\"bht\"),\n",
    "        make_roling_lag(df[\"dp_tubing\"], name=\"dp_tubing\"),\n",
    "        make_roling_lag(df[\"AVG_CHOKE_SIZE_P\"], name=\"AVG_CHOKE_SIZE_P\")\n",
    "    ],\n",
    "    axis=\"columns\",\n",
    ")\n",
    "X = lagged_df.copy().fillna(0.0)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c64153e4-dbfb-46b3-9e6f-4e13ed9d6a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_step_1</th>\n",
       "      <th>y_step_2</th>\n",
       "      <th>y_step_3</th>\n",
       "      <th>y_step_4</th>\n",
       "      <th>y_step_5</th>\n",
       "      <th>y_step_6</th>\n",
       "      <th>y_step_7</th>\n",
       "      <th>y_step_8</th>\n",
       "      <th>y_step_9</th>\n",
       "      <th>y_step_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-07-24</th>\n",
       "      <td>9505.611429</td>\n",
       "      <td>108940.110000</td>\n",
       "      <td>257479.142857</td>\n",
       "      <td>112755.000000</td>\n",
       "      <td>137705.269214</td>\n",
       "      <td>141268.448264</td>\n",
       "      <td>161227.00</td>\n",
       "      <td>160270.49</td>\n",
       "      <td>160951.30</td>\n",
       "      <td>160232.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-25</th>\n",
       "      <td>108940.110000</td>\n",
       "      <td>257479.142857</td>\n",
       "      <td>112755.000000</td>\n",
       "      <td>137705.269214</td>\n",
       "      <td>141268.448264</td>\n",
       "      <td>161227.000000</td>\n",
       "      <td>160270.49</td>\n",
       "      <td>160951.30</td>\n",
       "      <td>160232.47</td>\n",
       "      <td>159483.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-28</th>\n",
       "      <td>257479.142857</td>\n",
       "      <td>112755.000000</td>\n",
       "      <td>137705.269214</td>\n",
       "      <td>141268.448264</td>\n",
       "      <td>161227.000000</td>\n",
       "      <td>160270.490000</td>\n",
       "      <td>160951.30</td>\n",
       "      <td>160232.47</td>\n",
       "      <td>159483.76</td>\n",
       "      <td>162196.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-29</th>\n",
       "      <td>112755.000000</td>\n",
       "      <td>137705.269214</td>\n",
       "      <td>141268.448264</td>\n",
       "      <td>161227.000000</td>\n",
       "      <td>160270.490000</td>\n",
       "      <td>160951.300000</td>\n",
       "      <td>160232.47</td>\n",
       "      <td>159483.76</td>\n",
       "      <td>162196.78</td>\n",
       "      <td>161999.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-31</th>\n",
       "      <td>137705.269214</td>\n",
       "      <td>141268.448264</td>\n",
       "      <td>161227.000000</td>\n",
       "      <td>160270.490000</td>\n",
       "      <td>160951.300000</td>\n",
       "      <td>160232.470000</td>\n",
       "      <td>159483.76</td>\n",
       "      <td>162196.78</td>\n",
       "      <td>161999.01</td>\n",
       "      <td>160095.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-04</th>\n",
       "      <td>87504.870000</td>\n",
       "      <td>87798.790000</td>\n",
       "      <td>88650.380000</td>\n",
       "      <td>88563.480000</td>\n",
       "      <td>89379.120000</td>\n",
       "      <td>89482.000000</td>\n",
       "      <td>90470.31</td>\n",
       "      <td>90540.97</td>\n",
       "      <td>90810.01</td>\n",
       "      <td>88042.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-05</th>\n",
       "      <td>87798.790000</td>\n",
       "      <td>88650.380000</td>\n",
       "      <td>88563.480000</td>\n",
       "      <td>89379.120000</td>\n",
       "      <td>89482.000000</td>\n",
       "      <td>90470.310000</td>\n",
       "      <td>90540.97</td>\n",
       "      <td>90810.01</td>\n",
       "      <td>88042.16</td>\n",
       "      <td>90188.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-06</th>\n",
       "      <td>88650.380000</td>\n",
       "      <td>88563.480000</td>\n",
       "      <td>89379.120000</td>\n",
       "      <td>89482.000000</td>\n",
       "      <td>90470.310000</td>\n",
       "      <td>90540.970000</td>\n",
       "      <td>90810.01</td>\n",
       "      <td>88042.16</td>\n",
       "      <td>90188.97</td>\n",
       "      <td>91890.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-07</th>\n",
       "      <td>88563.480000</td>\n",
       "      <td>89379.120000</td>\n",
       "      <td>89482.000000</td>\n",
       "      <td>90470.310000</td>\n",
       "      <td>90540.970000</td>\n",
       "      <td>90810.010000</td>\n",
       "      <td>88042.16</td>\n",
       "      <td>90188.97</td>\n",
       "      <td>91890.07</td>\n",
       "      <td>91579.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-08</th>\n",
       "      <td>89379.120000</td>\n",
       "      <td>89482.000000</td>\n",
       "      <td>90470.310000</td>\n",
       "      <td>90540.970000</td>\n",
       "      <td>90810.010000</td>\n",
       "      <td>88042.160000</td>\n",
       "      <td>90188.97</td>\n",
       "      <td>91890.07</td>\n",
       "      <td>91579.73</td>\n",
       "      <td>93289.481507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1110 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 y_step_1       y_step_2       y_step_3       y_step_4  \\\n",
       "date                                                                     \n",
       "2013-07-24    9505.611429  108940.110000  257479.142857  112755.000000   \n",
       "2013-07-25  108940.110000  257479.142857  112755.000000  137705.269214   \n",
       "2013-07-28  257479.142857  112755.000000  137705.269214  141268.448264   \n",
       "2013-07-29  112755.000000  137705.269214  141268.448264  161227.000000   \n",
       "2013-07-31  137705.269214  141268.448264  161227.000000  160270.490000   \n",
       "...                   ...            ...            ...            ...   \n",
       "2016-09-04   87504.870000   87798.790000   88650.380000   88563.480000   \n",
       "2016-09-05   87798.790000   88650.380000   88563.480000   89379.120000   \n",
       "2016-09-06   88650.380000   88563.480000   89379.120000   89482.000000   \n",
       "2016-09-07   88563.480000   89379.120000   89482.000000   90470.310000   \n",
       "2016-09-08   89379.120000   89482.000000   90470.310000   90540.970000   \n",
       "\n",
       "                 y_step_5       y_step_6   y_step_7   y_step_8   y_step_9  \\\n",
       "date                                                                        \n",
       "2013-07-24  137705.269214  141268.448264  161227.00  160270.49  160951.30   \n",
       "2013-07-25  141268.448264  161227.000000  160270.49  160951.30  160232.47   \n",
       "2013-07-28  161227.000000  160270.490000  160951.30  160232.47  159483.76   \n",
       "2013-07-29  160270.490000  160951.300000  160232.47  159483.76  162196.78   \n",
       "2013-07-31  160951.300000  160232.470000  159483.76  162196.78  161999.01   \n",
       "...                   ...            ...        ...        ...        ...   \n",
       "2016-09-04   89379.120000   89482.000000   90470.31   90540.97   90810.01   \n",
       "2016-09-05   89482.000000   90470.310000   90540.97   90810.01   88042.16   \n",
       "2016-09-06   90470.310000   90540.970000   90810.01   88042.16   90188.97   \n",
       "2016-09-07   90540.970000   90810.010000   88042.16   90188.97   91890.07   \n",
       "2016-09-08   90810.010000   88042.160000   90188.97   91890.07   91579.73   \n",
       "\n",
       "                y_step_10  \n",
       "date                       \n",
       "2013-07-24  160232.470000  \n",
       "2013-07-25  159483.760000  \n",
       "2013-07-28  162196.780000  \n",
       "2013-07-29  161999.010000  \n",
       "2013-07-31  160095.110000  \n",
       "...                   ...  \n",
       "2016-09-04   88042.160000  \n",
       "2016-09-05   90188.970000  \n",
       "2016-09-06   91890.070000  \n",
       "2016-09-07   91579.730000  \n",
       "2016-09-08   93289.481507  \n",
       "\n",
       "[1110 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eight-week forecast\n",
    "y = make_multistep_target(df[\"QG\"], steps=10).dropna()\n",
    "\n",
    "# Shifting has created indexes that don't match. Only keep times for\n",
    "# which we have both targets and features.\n",
    "y, X = y.align(X, join='inner', axis=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a426a904-2c6e-4859-b35a-21c0f2dac691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y_step_1  y_step_2  y_step_3  y_step_4  y_step_5  y_step_6  y_step_7  \\\n",
      "0  0.000000  0.256852  0.726162  0.268906  0.347736  0.358994  0.422053   \n",
      "1  0.297135  0.726162  0.268906  0.347736  0.358994  0.422053  0.419031   \n",
      "2  0.741006  0.268906  0.347736  0.358994  0.422053  0.419031  0.421182   \n",
      "3  0.308534  0.347736  0.358994  0.422053  0.419031  0.421182  0.418911   \n",
      "4  0.383092  0.358994  0.422053  0.419031  0.421182  0.418911  0.416545   \n",
      "\n",
      "   y_step_8  y_step_9  y_step_10  \n",
      "0  0.419031  0.421182   0.418911  \n",
      "1  0.421182  0.418911   0.416545  \n",
      "2  0.418911  0.416545   0.425117  \n",
      "3  0.416545  0.425117   0.424492  \n",
      "4  0.425117  0.424492   0.418477  \n",
      "(1110, 10)\n"
     ]
    }
   ],
   "source": [
    "# Normalize features \n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "scaled_X = scaler_X.fit_transform(X.values)\n",
    "series_X = pd.DataFrame(scaled_X, columns=X.columns)\n",
    "scaled_y = scaler_y.fit_transform(y.values)\n",
    "series_y = pd.DataFrame(scaled_y, columns=y.columns)\n",
    "print(series_y.head())\n",
    "print(series_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d699e0a0-3b71-4a74-beda-f9435272c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training (70%) and test (30%)\n",
    "nrow = round(0.7*X.shape[0])\n",
    "X_train = series_X.iloc[:nrow, :]\n",
    "y_train = series_y[:nrow]\n",
    "X_test = series_X.iloc[nrow:,:]\n",
    "y_test = series_y[nrow:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bef8ebb-d8d6-436a-a24b-3d71a05c5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.values.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "# X_test = X_test.values.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde89bc-008e-4e52-8e38-1640f0be2438",
   "metadata": {},
   "source": [
    "<h5 style=\"color:rgba(0, 0, 178, 0.6);\">Create a function that build a dynamic model that can change the shape of the NN model with hyper parameters(hp) parameters</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bf5eba6-9bf9-4f8f-9173-b10e818c3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp ======> hyper parameters = [number_nuron_layer1, number_nuron_layer2, number_nuron_layer3,\n",
    "#                          number_nuron_layer4, Activation_fuctin_layer1, Activaiton_function_layer2,\n",
    "#                     Activation_fuctin_layer3, Activation_fuctin_layer4, If for layer1 have Drop_out=1 else 0,\n",
    "#         If for layer2 have Drop_out=1 else 0, If for layer3 have Drop_out=1 else 0, If for layer4 have Drop_out=1 else 0,\n",
    "#     If for layer1 have batch_norm=1 else 0, If for layer2 have batch_norm=1 else 0, If for layer1 have batch_norm=3 else 0,\n",
    "#                       If for layer1 have batch_norm=1 else 0, learning_rate, batch_size]\n",
    "\n",
    "\n",
    "# in this function we create a function that can build model that can chane evry time\n",
    "\n",
    "def dynamic_model(hp, train=X_train):\n",
    "\n",
    "\n",
    "    activation_function = [\"relu\",\"sigmoid\",\"softmax\",\"softsign\",\n",
    "                           \"tanh\",\"selu\",\"elu\" ,\"exponential\",\n",
    "                           \"leaky_relu\",\"relu6\",\"silu\",\"gelu\",\n",
    "                           \"hard_sigmoid\",\"linear\",\"mish\",\"log_softmax\"]\n",
    "    \n",
    "\n",
    "    input_layer = keras.layers.Input(shape=(93,))\n",
    "    layer1 = keras.layers.Dense([93, hp[0]], activation_function[int(hp[4])], name=\"layer1\")(input_layer)\n",
    "    \n",
    "#     in this sectino we have 4 layer  so that we have 4 section for dscetion that we have in each layer DropOut or BatchNorm\n",
    "#   this is layer1 we have 4 condition:\n",
    "    if ((hp[8] == 1) & (hp[12] == 1)):\n",
    "        drop1 = keras.layers.Dropout(0.3)(layer1)\n",
    "        norm1 = keras.layers.BatchNormalization()(drop1)\n",
    "        layer2 = keras.layers.Dense(hp[1], activation_function[int(hp[5])], name=\"layer2\")(norm1)\n",
    "    elif ((hp[8] == 1) & (hp[12] == 0)):\n",
    "        drop1 = keras.layers.Dropout(0.3)(layer1)\n",
    "        layer2 = keras.layers.Dense(hp[1], activation_function[int(hp[5])], name=\"layer2\")(drop1)\n",
    "    elif ((hp[8] == 0) & (hp[12] == 1)):\n",
    "        norm1 = keras.layers.BatchNormalization()(layer1)\n",
    "        layer2 = keras.layers.Dense(hp[1], activation_function[int(hp[5])], name=\"layer2\")(norm1)\n",
    "    else:\n",
    "        layer2 = keras.layers.Dense(hp[1], activation_function[int(hp[5])], name=\"layer2\")(layer1)\n",
    "        \n",
    "#    layer2:     \n",
    "    if ((hp[9] == 1) & (hp[13] == 1)):\n",
    "        drop2 = keras.layers.Dropout(0.3)(layer2)\n",
    "        norm2 = keras.layers.BatchNormalization()(drop2)\n",
    "        layer3 = keras.layers.Dense(hp[2], activation_function[int(hp[6])], name=\"layer3\")(norm2)\n",
    "    elif ((hp[9] == 1) & (hp[13] == 0)):\n",
    "        drop2 = keras.layers.Dropout(0.3)(layer2)\n",
    "        layer3 = keras.layers.Dense(hp[2], activation_function[int(hp[6])], name=\"layer3\")(drop2)\n",
    "    elif ((hp[9] == 0) & (hp[13] == 1)):\n",
    "        norm2 = keras.layers.BatchNormalization()(layer2)\n",
    "        layer3 = keras.layers.Dense(hp[2], activation_function[int(hp[6])], name=\"layer3\")(norm2)\n",
    "    else:\n",
    "        layer3 = keras.layers.Dense(hp[2], activation_function[int(hp[6])], name=\"layer3\")(layer2)\n",
    "        \n",
    "#     layer3 :         \n",
    "    if ((hp[10] == 1) & (hp[14] == 1)):\n",
    "        drop3 = keras.layers.Dropout(0.3)(layer3)\n",
    "        norm3 = keras.layers.BatchNormalization()(drop3)\n",
    "        layer4 = keras.layers.Dense(hp[3], activation_function[int(hp[7])], name=\"layer4\")(norm3)\n",
    "    elif ((hp[10] == 1) & (hp[14] == 0)):\n",
    "        drop3 = keras.layers.Dropout(0.3)(layer3)\n",
    "        layer4 = keras.layers.Dense(hp[3], activation_function[int(hp[7])], name=\"layer4\")(drop3)\n",
    "    elif ((hp[10] == 0) & (hp[14] == 1)):\n",
    "        norm3 = keras.layers.BatchNormalization()(layer3)\n",
    "        layer4 = keras.layers.Dense(hp[3], activation_function[int(hp[7])], name=\"layer4\")(norm3)\n",
    "    else:\n",
    "        layer4 = keras.layers.Dense(hp[3], activation_function[int(hp[7])], name=\"layer4\")(layer3)\n",
    "        \n",
    "#    layer4:        \n",
    "    if ((hp[11] == 1) & (hp[15] == 1)):\n",
    "        drop4 = keras.layers.Dropout(0.3)(layer4)\n",
    "        norm4 = keras.layers.BatchNormalization()(drop4)\n",
    "        output_layer = keras.layers.Dense(1, \"linear\", name=\"output_layer\")(norm4)\n",
    "    elif ((hp[11] == 1) & (hp[15] == 0)):\n",
    "        drop4 = keras.layers.Dropout(0.3)(layer4)\n",
    "        output_layer = keras.layers.Dense(1, \"linear\", name=\"output_layer\")(drop4)\n",
    "    elif ((hp[11] == 0) & (hp[15] == 1)):\n",
    "        norm4 = keras.layers.BatchNormalization()(layer4)\n",
    "        output_layer = keras.layers.Dense(1, \"linear\", name=\"output_layer\")(norm4)\n",
    "    else:\n",
    "        output_layer = keras.layers.Dense(1, \"linear\", name=\"output_layer\")(layer4)\n",
    "\n",
    "#     at last we create final model        \n",
    "    model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "#     in this section we complie the model    \n",
    "    optimizer =keras.optimizers.Adam(learning_rate=hp[16])\n",
    "    model.compile(loss=\"mae\", optimizer=optimizer, metrics=[\"mse\"])\n",
    "\n",
    "    # wright the callbacks that we need\n",
    "#     checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_checkpoints.h5\", save_weights_only=True,best_only=True)\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True)\n",
    "    \n",
    "    # fit the model\n",
    "    history = model.fit(X_train,\n",
    "                         y_train, \n",
    "                        validation_data=(X_test, y_test),\n",
    "                        callbacks=[early_stopping_cb],\n",
    "                        batch_size=int(hp[17]),\n",
    "                        epochs=1000,\n",
    "                        verbose=0)\n",
    "    \n",
    "#     in this section we complie the model\n",
    "    val_pred = model.predict(X_test)\n",
    "#   because we r2_score dont work with nan values we chane nan value with -999\n",
    "    val_pred[np.isnan(val_pred)] = -999\n",
    "        \n",
    "    solution_fitness = r2_score(y_test, val_pred)\n",
    "    print(solution_fitness)\n",
    " \n",
    "    return solution_fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "172e390a-0699-4f25-bcf5-6abd90a9b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_creator(num_solutions=100):\n",
    "    hps = pd.DataFrame(columns=[\n",
    "                                \"nurn1\",\"nurn2\",\"nurn3\",\"nurn4\",\n",
    "                                \"Active1\",\"Active2\",\"Active3\",\"Active4\",\n",
    "                                \"Drop1\", \"Drop2\", \"Drop3\", \"Drop4\",\n",
    "                                \"Norm1\", \"Norm2\", \"Norm3\", \"Norm4\",\n",
    "                                \"Learn_rate\", \"batch_size\"\n",
    "                               ])\n",
    "    \n",
    "    hps[\"nurn1\"], hps[\"nurn2\"] = [random.randint(10, 200) for _ in range(num_solutions)], [random.randint(10, 200) for _ in range(num_solutions)]\n",
    "    hps[\"nurn3\"], hps[\"nurn4\"] = [random.randint(10, 200) for _ in range(num_solutions)], [random.randint(10, 200) for _ in range(num_solutions)]\n",
    "    \n",
    "    hps[\"Active1\"], hps[\"Active2\"] = [random.randint(0, 15) for _ in range(num_solutions)], [random.randint(0, 15) for _ in range(num_solutions)]\n",
    "    hps[\"Active3\"], hps[\"Active4\"] = [random.randint(0, 15) for _ in range(num_solutions)], [random.randint(0, 15) for _ in range(num_solutions)]\n",
    "                                                                                 \n",
    "    hps[\"Drop1\"], hps[\"Drop2\"] = [random.choice([0, 1]) for _ in range(num_solutions)], [random.choice([0, 1]) for _ in range(num_solutions)]\n",
    "    hps[\"Drop3\"], hps[\"Drop4\"] = [random.choice([0, 1]) for _ in range(num_solutions)], [random.choice([0, 1]) for _ in range(num_solutions)]\n",
    "    \n",
    "    hps[\"Norm1\"], hps[\"Norm2\"] = [random.choice([0, 1]) for _ in range(num_solutions)], [random.choice([0, 1]) for _ in range(num_solutions)]\n",
    "    hps[\"Norm3\"], hps[\"Norm4\"] = [random.choice([0, 1]) for _ in range(num_solutions)], [random.choice([0, 1]) for _ in range(num_solutions)]\n",
    "    \n",
    "    hps[\"Learn_rate\"] = [random.choice([0.001, 0.01, 0.0001, 0.00001, 0.1, 0.000001, 0.0000001]) for _ in range(num_solutions)]\n",
    "    hps[\"batch_size\"] = [random.randint(30, 300) for _ in range(num_solutions)]\n",
    "    \n",
    "\n",
    "    return hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c10f4eb-64ec-4727-a3c3-47ded9806866",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: TrackedList",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 93\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m swarm_best_position, swarm_best_fitness\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Run the PSO algorithm on the Rastrigin function\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m solution, fitness \u001b[38;5;241m=\u001b[39m \u001b[43mpso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Print the solution and fitness value\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolution:\u001b[39m\u001b[38;5;124m'\u001b[39m, solution)\n",
      "Cell \u001b[1;32mIn[38], line 13\u001b[0m, in \u001b[0;36mpso\u001b[1;34m(num_particles, max_iter, w, c1, c2)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Initialize the best positions and fitness values\u001b[39;00m\n\u001b[0;32m     12\u001b[0m best_positions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(particles)\n\u001b[1;32m---> 13\u001b[0m best_fitness \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mdynamic_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m particles])\n\u001b[0;32m     14\u001b[0m swarm_best_position \u001b[38;5;241m=\u001b[39m best_positions[np\u001b[38;5;241m.\u001b[39margmax(best_fitness)]\n\u001b[0;32m     15\u001b[0m swarm_best_fitness \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(best_fitness)\n",
      "Cell \u001b[1;32mIn[36], line 21\u001b[0m, in \u001b[0;36mdynamic_model\u001b[1;34m(hp, train)\u001b[0m\n\u001b[0;32m     14\u001b[0m     activation_function \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftsign\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melu\u001b[39m\u001b[38;5;124m\"\u001b[39m ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexponential\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleaky_relu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu6\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msilu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgelu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhard_sigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmish\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_softmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     20\u001b[0m     input_layer \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m93\u001b[39m,))\n\u001b[1;32m---> 21\u001b[0m     layer1 \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m93\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_function\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#     in this sectino we have 4 layer  so that we have 4 section for dscetion that we have in each layer DropOut or BatchNorm\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#   this is layer1 we have 4 condition:\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ((hp[\u001b[38;5;241m8\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (hp[\u001b[38;5;241m12\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py:495\u001b[0m, in \u001b[0;36mstandardize_dtype\u001b[1;34m(dtype)\u001b[0m\n\u001b[0;32m    492\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39mALLOWED_DTYPES:\n\u001b[1;32m--> 495\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dtype\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid dtype: TrackedList"
     ]
    }
   ],
   "source": [
    "# num_particles ==> number of rnadom input that generate\n",
    "# max_iter ==> number of iteration that function use to solve the problem\n",
    "# w and c1 and c2 ==> constant parameters this are hayper parameter\n",
    "\n",
    "\n",
    "def pso(num_particles=100, max_iter=20, w=0.5, c1=1, c2=2):\n",
    "    # Initialize particles and velocities\n",
    "    particles = hp_creator(num_solutions=num_particles).values\n",
    "    velocities = np.zeros((num_particles, len(particles[0,:])))\n",
    "\n",
    "    # Initialize the best positions and fitness values\n",
    "    best_positions = np.copy(particles)\n",
    "    best_fitness = np.array([dynamic_model(p) for p in particles])\n",
    "    swarm_best_position = best_positions[np.argmax(best_fitness)]\n",
    "    swarm_best_fitness = np.max(best_fitness)\n",
    "    \n",
    "    # Iterate through the specified number of iterations, updating the velocity and position of each particle at each iteration\n",
    "    for k in range(max_iter):\n",
    "        # Update velocities\n",
    "        r1 = np.random.uniform(0, 1, (num_particles, 18))\n",
    "        r2 = np.random.uniform(0, 1, (num_particles, 18))\n",
    "        velocities = w * velocities + c1 * r1 * (best_positions - particles) + c2 * r2 * (swarm_best_position - particles)\n",
    "\n",
    "        # Update positions\n",
    "        particles += velocities\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "#       in this section we need to the updated positions in bonderys that we need so we set ruls to it\n",
    "#       ferst for for check each particle and secend for to check each parameters\n",
    "        for i, hp in enumerate(particles):\n",
    "            for j, param in enumerate(hp):\n",
    "                #------------------------------------------------------------------------------------------------\n",
    "                #bounders for number of nurouns in each leayer\n",
    "                if (j>=0)&(j<4):\n",
    "                    while (10>particles[i,j])or(200<particles[i,j]):\n",
    "                        if particles[i,j]<10:\n",
    "                            particles[i,j] = 10 + (10-int(particles[i,j]))\n",
    "                        elif particles[i,j]>200:\n",
    "                            particles[i,j] = 200-(int(particles[i,j])-200)\n",
    "                    particles[i,j] = int(particles[i,j])\n",
    "               #--------------------------------------------------------------------------------------------------\n",
    "                #bounders for which activation we should use    \n",
    "                if (j>=4)&(j<8):\n",
    "                    while (0>particles[i,j])or(15<particles[i,j]):\n",
    "                        if particles[i,j]<0:\n",
    "                            particles[i,j] = 0 - int(round(particles[i,j]))\n",
    "                        elif particles[i,j]>15:\n",
    "                            particles[i,j] = 15-(int(round(particles[i,j])-15))\n",
    "                    particles[i,j] = int(round(particles[i,j]))\n",
    "              #----------------------------------------------------------------------------------------------------\n",
    "                #bounders for if we have Dropuout or Batchnormalize or not\n",
    "                if (j>=8)&(j<16):\n",
    "                    if particles[i,j]<=0.5:\n",
    "                        particles[i,j] = 0\n",
    "                    elif particles[i,j]>0.5:\n",
    "                        particles[i,j] = 1\n",
    "             #------------------------------------------------------------------------------------------------------\n",
    "                #bounders for learning rate\n",
    "                if j==16:\n",
    "                    while (10e-7>particles[i,j])or(0.1<particles[i,j]):\n",
    "                        if particles[i,j]<10e-7:\n",
    "                            particles[i,j] = 10e-7 + (10e-7-particles[i,j])\n",
    "                        elif particles[i,j]>0.1:\n",
    "                            particles[i,j] = 0.1-(particles[i,j]-0.1)\n",
    "            #------------------------------------------------------------------------------------------------------\n",
    "                #bounders for batch size\n",
    "                if j==17:\n",
    "                    while (30>particles[i,j])or(300<particles[i,j]):\n",
    "                        if particles[i,j]<30:\n",
    "                            particles[i,j] = 30 + (30-int(particles[i,j]))\n",
    "                        elif particles[i,j]>300:\n",
    "                            particles[i,j] = 300-(int(particles[i,j])-300)\n",
    "                    particles[i,j] = int(particles[i,j])\n",
    "#------------------------------------------------------------------------------------------------------------------\n",
    "                    \n",
    "        # Evaluate fitness of each particle\n",
    "        print(\"=========================================================================\")\n",
    "        print(\"iter:\",k)\n",
    "        fitness_values = np.array([dynamic_model(p) for p in particles])\n",
    "        print(\"==========================================================================\")\n",
    "        # Update best positions and fitness values\n",
    "        improved_indices = np.where(fitness_values > best_fitness)\n",
    "        best_positions[improved_indices] = particles[improved_indices]\n",
    "        best_fitness[improved_indices] = fitness_values[improved_indices]\n",
    "        if np.max(fitness_values) > swarm_best_fitness:\n",
    "            swarm_best_position = particles[np.argmax(fitness_values)]\n",
    "            swarm_best_fitness = np.max(fitness_values)\n",
    "\n",
    "    # Return the best solution found by the PSO algorithm\n",
    "    return swarm_best_position, swarm_best_fitness\n",
    "\n",
    "\n",
    "# Run the PSO algorithm on the Rastrigin function\n",
    "solution, fitness = pso(max_iter=5)\n",
    "\n",
    "# Print the solution and fitness value\n",
    "print('Solution:', solution)\n",
    "print('Fitness:', fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5434de41-c85c-4f08-9e60-61d0947c0f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
